data_config: "config/data/data_config.yaml"
model_dir: '/mnt/win/UMoncton/Doctorat/dev/dlbd/results/models/local/run1'
clean_empty_models: True

logs:
  log_dir: "logs/gradient_tape/run1"
  use_version: True

# name : MODEL_NAME


id: "{databases_options--spectrogram--n_mels}"
id_prefixes:
  databases_options--spectrogram--n_mels: "_nmels-"

##
## Databases
##

databases: ['arctic_complete']
databases_options:
  spectrogram:
    n_fft: 2048
    hop_length: 1024
    n_mels: 32
    sample_rate: "original"

##
## Model options
##

n_epochs: 20
learning_rate: 0.001
epoch_save_step: 5
# from_epoch: 100

learn_log: 0
do_augmentation: 1
A: 0.001 # biotic 
B: 10.0 #biotic
ensemble_members: 1
training_balanced: True
pixels_in_sec: 20

batch_size: 128
do_batch_norm: 1
# input_size: 25
# hww_spec: 20
# hww_gt: 10
spec_height: 32
channels: 4
num_filters: 128
num_dense_units: 512
conv_filter_width: 4
wiggle_room: 5
dropout: 0.5

# use_weights:
#   version:
#   path:
#   name:



scenarios:
  # - name: "DLBDL_A"
  #   class: "dlbd.models.dlbd.DLBDLite"
  - name: "DLBDL_A2"
    class: "dlbd.models.dlbd.DLBDLite"
    pixels_in_sec: 44
    spec_height: 64
    databases_options:
      spectrogram:
        n_fft: 2048
        hop_length: 512
        n_mels: 64
        sample_rate: "original"
    # transfer_learning: True
    # n_epochs: 100
    # learning_rate: 0.001
    # # fine_tuning:
    # #   n_epochs: 20
    # #   learning_rate: 0.00001 
    # weights_opts:
    #     name: "DLBDL_Ci_nmels-32"
    #     model_dir: '/mnt/win/UMoncton/Doctorat/dev/dlbd/results/models/gpu/run3'


